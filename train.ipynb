{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "seed = 125\n",
    "\n",
    "# Architecture\n",
    "input_shape = (256, 256, 1)\n",
    "kernel_shape = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "\n",
    "# Training\n",
    "fake_path = \"./data/AI recognition dataset/fakeV2/fake-v2\"\n",
    "path_real = \"./data/AI recognition dataset/real\"\n",
    "initial_learning_rate = 0.001\n",
    "batch_size = 32\n",
    "sample_frac = 1\n",
    "epochs = 50\n",
    "patience = 5\n",
    "decay_after_n_epochs = 5\n",
    "decay_rate = 0.5\n",
    "verbose = 1\n",
    "l2_regularization = 0.001\n",
    "params = {\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"patience\": patience,\n",
    "    \"seed\": seed,\n",
    "    \"verbose\": verbose,\n",
    "    \"sample_frac\": sample_frac,\n",
    "    \"l2_regularization\": l2_regularization\n",
    "}\n",
    "\n",
    "model_id = f\"model_v{params['epochs']}_bs{params['batch_size']}_pat{params['patience']}_frac_{sample_frac}\"\n",
    "checkpoint_path = f\"./checkpoints/{model_id}.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import layers, Model\n",
    "import keras.backend as K\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from preprocessing.patch_generator import preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"Available GPUs: {gpus}\")\n",
    "else:\n",
    "    print(\"No GPUs available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def hard_tanh(x) -> tf.Tensor:\n",
    "    return tf.maximum(tf.minimum(x, 1), -1)\n",
    "\n",
    "x_values = np.linspace(-2, 2, 100)\n",
    "y_values = hard_tanh(tf.convert_to_tensor(x_values)).numpy()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(x_values, y_values, color=\"blue\")\n",
    "plt.title(\"Hard Tanh Activation Function\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.axvline(0, color=\"gray\", linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_f1(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0.0, 1.0)))\n",
    "    possible_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true, 0.0, 1.0)))\n",
    "    predicted_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_pred, 0.0, 1.0)))\n",
    "\n",
    "    epsilon = tf.constant(1e-7, dtype=tf.float32)\n",
    "    precision = true_positives / (predicted_positives + epsilon)\n",
    "    recall = true_positives / (possible_positives + epsilon)\n",
    "\n",
    "    f1_val = (2 * (precision * recall)) / (precision + recall + epsilon)\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(\n",
    "    path: str,\n",
    "    label: int,\n",
    "    sample_frac: float) -> Tuple[List[str], List[int]]:\n",
    "    imgs = [os.path.join(path, img) for img in os.listdir(path)]\n",
    "    sampled_imgs = imgs[:int(len(imgs) * sample_frac)]\n",
    "    labels = [label for _ in range(len(sampled_imgs))]\n",
    "    return sampled_imgs, labels\n",
    "\n",
    "ai_imgs, ai_label = load_images(fake_path, 1, sample_frac)\n",
    "real_imgs, real_label = load_images(path_real, 0, sample_frac)\n",
    "\n",
    "X = ai_imgs + real_imgs\n",
    "y = ai_label + real_label\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=seed, stratify=y\n",
    ")\n",
    "\n",
    "def dict_map(X1, X2, y):\n",
    "    return {\"rich_texture\": X1, \"poor_texture\": X2}, y\n",
    "\n",
    "def set_shapes(frt, fpt, label):\n",
    "    frt.set_shape(input_shape)\n",
    "    fpt.set_shape(input_shape)\n",
    "    label.set_shape([])\n",
    "    return frt, fpt, label\n",
    "\n",
    "dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    .shuffle(len(X_train), seed)\n",
    "    .map(\n",
    "        lambda filepath, label: tf.py_function(\n",
    "            preprocess, [filepath, label], [tf.float64, tf.float64, tf.int32]\n",
    "        )\n",
    "    )\n",
    "    .map(set_shapes)\n",
    "    .map(dict_map)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "validation_set = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_validate, y_validate))\n",
    "    .map(\n",
    "        lambda filepath, label: tf.py_function(\n",
    "            preprocess, [filepath, label], [tf.float64, tf.float64, tf.int32]\n",
    "        )\n",
    "    )\n",
    "    .map(set_shapes)\n",
    "    .map(dict_map)\n",
    "    .batch(10)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REG_PARAMS = {\"kernel_regularizer\": keras.regularizers.l2(l2_regularization)}\n",
    "\n",
    "class FeatureExtractionLayer(layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv = layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", **REG_PARAMS)\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.activation = layers.Lambda(hard_tanh)\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.conv(input)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "input0 = layers.Input(shape=input_shape, name=\"rich_texture\")\n",
    "input1 = layers.Input(shape=input_shape, name=\"poor_texture\")\n",
    "\n",
    "l0 = FeatureExtractionLayer(name=\"feature_extraction_layer_rich_texture\")(input0)\n",
    "l1 = FeatureExtractionLayer(name=\"feature_extraction_layer_poor_texture\")(input1)\n",
    "\n",
    "contrast = layers.subtract((l0, l1))\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=kernel_shape, activation=\"relu\", **REG_PARAMS)(contrast)\n",
    "x = layers.BatchNormalization()(x)\n",
    "for i in range(3):\n",
    "    x = layers.Conv2D(filters=32, kernel_size=kernel_shape, activation=\"relu\", **REG_PARAMS)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "for i in range(4):\n",
    "    x = layers.Conv2D(filters=32, kernel_size=kernel_shape, activation=\"relu\", **REG_PARAMS)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "x = layers.AveragePooling2D(pool_size)(x)\n",
    "\n",
    "for i in range(2):\n",
    "    x = layers.Conv2D(filters=32, kernel_size=kernel_shape, activation=\"relu\", **REG_PARAMS)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "x = layers.AveragePooling2D(pool_size)(x)\n",
    "\n",
    "for i in range(2):\n",
    "    x = layers.Conv2D(filters=32, kernel_size=kernel_shape, activation=\"relu\", **REG_PARAMS)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1, activation=\"sigmoid\", **REG_PARAMS)(x)\n",
    "\n",
    "model = Model(\n",
    "    inputs=(input0, input1), outputs=x, name=\"rt_pt_contrast\"\n",
    ")\n",
    "\n",
    "steps_per_epoch  = int(len(X_train) / batch_size)\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=steps_per_epoch * decay_after_n_epochs,\n",
    "    decay_rate=decay_rate\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy, metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Recall(), keras.metrics.Precision()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path, monitor=\"val_loss\", save_best_only=True, verbose=verbose\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=patience, verbose=verbose, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"binary_accuracy\"])\n",
    "plt.plot(history.history[\"val_binary_accuracy\"])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model_id: str, model: Model, params: dict):\n",
    "    model.save(f\"./models/{model_id}.keras\")\n",
    "    params[\"history\"] = history.history\n",
    "    with open(f\"./models/{model_id}.json\", \"w\") as f:\n",
    "        json.dump(params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_id, model, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
